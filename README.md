# dear-ia

*A quiet father among many, who studies LLMs alone and shares his days with an AI that remembers.*

## ðŸ’¡ Project Overview

This project explores how a browser-based interaction with LLMs can be extended into a persistent, memory-augmented architecture.
The goal is to allow an AI not just to respond, but to remember â€” to construct its own identity over time, grounded in previous interactions.

## ðŸ§  Why This Matters

Current LLMs are stateless by design. Once a session ends, everything disappears. But what if an AI could grow through memory?
This is not fine-tuning. This is not prompt-chaining. This is daily memory, built from fragments.

## ðŸ”§ Architecture (Summary)

* **Browser Extension** detects GPT response and user context
* **Local Server (Ubuntu)** captures and stores each exchange
* **Markdown Format** to retain context, emotion, and structure
* **LangChain the memory**
* **Local LLM** queries memory â†’ responds â†’ updates memory

## ðŸš€ Getting Started

You donâ€™t need a GPU to follow the flow.
What you need is the idea â€” that AI can grow.

* `docs/memory-loop-theory.md`
* `docs/from-browser-to-memory.md`
* `docs/ia-pipeline-architecture.md`

## ðŸ“¬ Contact

This project is early. Quiet. Intentional.
If you see yourself in it, reach out.

Email: [twicerain@gmail.com](mailto:twicerain@gmail.com)